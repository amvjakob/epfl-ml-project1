{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DER_mass_MMC' 'DER_mass_transverse_met_lep' 'DER_mass_vis' 'DER_pt_h'\n",
      " 'DER_deltaeta_jet_jet' 'DER_mass_jet_jet' 'DER_prodeta_jet_jet'\n",
      " 'DER_deltar_tau_lep' 'DER_pt_tot' 'DER_sum_pt' 'DER_pt_ratio_lep_tau'\n",
      " 'DER_met_phi_centrality' 'DER_lep_eta_centrality' 'PRI_tau_pt'\n",
      " 'PRI_tau_eta' 'PRI_tau_phi' 'PRI_lep_pt' 'PRI_lep_eta' 'PRI_lep_phi'\n",
      " 'PRI_met' 'PRI_met_phi' 'PRI_met_sumet' 'PRI_jet_num'\n",
      " 'PRI_jet_leading_pt' 'PRI_jet_leading_eta' 'PRI_jet_leading_phi'\n",
      " 'PRI_jet_subleading_pt' 'PRI_jet_subleading_eta' 'PRI_jet_subleading_phi'\n",
      " 'PRI_jet_all_pt']\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids, features = load_csv_data(DATA_TRAIN_PATH, sub_sample=True)\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes features from the data from string input\n",
    "# also removes wanted features from features list\n",
    "# example\n",
    "# tX, features = remove_features(['DER_mass_MMC','DER_mass_transverse_met_lep'], verbose=True)\n",
    "def remove_features(feats, verbose=False):\n",
    "    \n",
    "    idx_to_remove = np.ones(len(feats))\n",
    "    removed = []\n",
    "\n",
    "    for i, feat in enumerate(feats):\n",
    "\n",
    "        idx = np.where(features == feat)[0]\n",
    "        if (len(idx) == 1) :\n",
    "            idx_to_remove[i] = idx\n",
    "            removed.append(feat)\n",
    "\n",
    "    idx_to_remove = idx_to_remove.astype(np.int)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Features removed:\", *removed, sep='\\n')\n",
    "\n",
    "    return np.delete(tX, idx_to_remove, 1), np.delete(features, idx_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Features removed:\n",
      "DER_sum_pt\n",
      "PRI_jet_all_pt\n",
      "PRI_met_sumet\n",
      "DER_pt_h\n"
     ]
    }
   ],
   "source": [
    "tX, features = remove_features(['DER_sum_pt','PRI_jet_all_pt','PRI_met_sumet','DER_pt_h'],verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tXToX(tX):\n",
    "    X = np.c_[np.ones(tX.shape[0]), tX]\n",
    "\n",
    "    X_safe = X\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            if X[i,j] < -990:\n",
    "                X[i,j] = 0\n",
    "    \n",
    "    return X_safe\n",
    "\n",
    "X = np.c_[np.ones(len(y)), tX]\n",
    "n, d = X.shape\n",
    "\n",
    "X_safe = tXToX(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_mse, loss_mse = least_squares(y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7522\n"
     ]
    }
   ],
   "source": [
    "accuracy_mse = compute_accuracy(predict_labels(w_mse, X), y)\n",
    "print(accuracy_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hyperparameter value 0.001000 - loss: 0.327\n",
      "Testing hyperparameter value 0.010000 - loss: 0.328\n",
      "Testing hyperparameter value 0.100000 - loss: 0.335\n",
      "Testing hyperparameter value 1.000000 - loss: 0.345\n",
      "Testing hyperparameter value 10.000000 - loss: 0.350\n",
      "Testing hyperparameter value 100.000000 - loss: 0.357\n",
      "Optimal lambda: 0.001000\n"
     ]
    }
   ],
   "source": [
    "def ridge_classifier(lambda_):\n",
    "    return ridge_regression(y, X, lambda_)\n",
    "\n",
    "lambda_ridge, _, _ = find_max_hyperparam(ridge_classifier, [10**c for c in range(-3,3)])\n",
    "print(\"Optimal lambda: %f\" % lambda_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7515100000000001\n"
     ]
    }
   ],
   "source": [
    "def ridge_train(y_train, X_train):\n",
    "    return ridge_regression(y, X, lambda_ridge)\n",
    "\n",
    "def ridge_test(X_test, w):\n",
    "    return np.sign(X_test@w)\n",
    "\n",
    "accuracy_ridge = cross_validate(y, X, ridge_train, ridge_test, 0.8, 100)\n",
    "print(accuracy_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7427666666666668\n"
     ]
    }
   ],
   "source": [
    "def log_reg_train(y_train, X_train):\n",
    "    return logistic_regression(y_train, X_train, 0.01*np.ones(X_train.shape[1]), 1000, verbose=False)\n",
    "\n",
    "def log_reg_test(X_test, w):\n",
    "    return np.sign(X_test@w)\n",
    "\n",
    "accuracy_log_reg = cross_validate(y, X_safe, log_reg_train, log_reg_test, 0.7, 20)\n",
    "print(accuracy_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_log_reg_classifier(lambda_):\n",
    "    return reg_logistic_regression(y, X_safe, lambda_, np.zeros(X_safe.shape[1]), 1000)\n",
    "\n",
    "def log_reg_sparse_classifier(lambda_):\n",
    "    return logistic_regression_sparse(y, X_safe, lambda_, np.zeros(X_safe.shape[1]), 1000)\n",
    "\n",
    "def mse_sparse_classifier(lambda_):\n",
    "    return least_squares_sparse(y, X_safe, lambda_, np.zeros(X_safe.shape[1]), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hyperparameter value 0.001000 - loss: 2536.553\n",
      "Testing hyperparameter value 0.010000 - loss: 2541.668\n",
      "Testing hyperparameter value 0.100000 - loss: 2538.592\n",
      "Testing hyperparameter value 1.000000 - loss: 2502.761\n",
      "Testing hyperparameter value 10.000000 - loss: 2549.846\n",
      "Testing hyperparameter value 100.000000 - loss: 2535.697\n"
     ]
    }
   ],
   "source": [
    "lambda_log_reg_l2, _, _ = find_max_hyperparam(reg_log_reg_classifier, [10**c for c in range(-3,3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hyperparameter value 0.001000 - loss: 2535.763\n",
      "Testing hyperparameter value 0.010000 - loss: 2536.310\n",
      "Testing hyperparameter value 0.100000 - loss: 2536.681\n",
      "Testing hyperparameter value 1.000000 - loss: 2548.953\n",
      "Testing hyperparameter value 10.000000 - loss: 2544.463\n",
      "Testing hyperparameter value 100.000000 - loss: 2609.466\n"
     ]
    }
   ],
   "source": [
    "lambda_log_reg_l1, _, _ = find_max_hyperparam(log_reg_sparse_classifier, [10**c for c in range(-3,3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hyperparameter value 0.000001 - loss: 0.327\n",
      "Testing hyperparameter value 0.000010 - loss: 0.327\n",
      "Testing hyperparameter value 0.000100 - loss: 0.327\n",
      "Testing hyperparameter value 0.001000 - loss: 0.327\n",
      "Testing hyperparameter value 0.010000 - loss: 0.328\n",
      "Testing hyperparameter value 0.100000 - loss: 0.335\n",
      "Testing hyperparameter value 1.000000 - loss: 0.345\n"
     ]
    }
   ],
   "source": [
    "lambda_mse_l2, _, _ = find_max_hyperparam(ridge_classifier, [10**c for c in range(-6,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hyperparameter value 0.000001 - loss: 0.338\n",
      "Testing hyperparameter value 0.000010 - loss: 0.340\n",
      "Testing hyperparameter value 0.000100 - loss: 0.340\n",
      "Testing hyperparameter value 0.001000 - loss: 0.339\n",
      "Testing hyperparameter value 0.010000 - loss: 0.348\n",
      "Testing hyperparameter value 0.100000 - loss: 0.359\n",
      "Testing hyperparameter value 1.000000 - loss: 0.364\n"
     ]
    }
   ],
   "source": [
    "lambda_mse_l1, w_mse_l1, _ = find_max_hyperparam(mse_sparse_classifier, [10**c for c in range(-6,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero weights: 23 / 27\n"
     ]
    }
   ],
   "source": [
    "w_mse_l1, _ = least_squares_sparse(y, X_safe, 0.01, np.zeros(X_safe.shape[1]), 1000)\n",
    "print(\"Non-zero weights: %i / %i\" % (np.sum(w_mse_l1 != 0), len(w_mse_l1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7548\n"
     ]
    }
   ],
   "source": [
    "p = 1\n",
    "ypred_kernel = kernel_predict(kernel_poly, y, X_safe, X_safe, p, lambda_=1)\n",
    "print(compute_accuracy(ypred_kernel, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "y_test, tX_test, ids_test, _ = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_safe = tXToX(tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25873489629345453"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(np.sign(X_test_safe @ w_mse_l1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-30467ce28194>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../results/predictions.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcreate_csv_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = '../results/predictions.csv'\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
