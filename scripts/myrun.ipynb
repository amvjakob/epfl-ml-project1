{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scripts\n",
    "from proj1_helpers import *\n",
    "from classifiers import *\n",
    "from solver import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch train data\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids, features = load_csv_data(DATA_TRAIN_PATH, sub_sample=False)\n",
    "X = tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DER_mass_MMC', 'DER_mass_transverse_met_lep', 'DER_mass_vis', 'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet', 'DER_prodeta_jet_jet', 'DER_deltar_tau_lep', 'DER_pt_tot', 'DER_sum_pt', 'DER_pt_ratio_lep_tau', 'DER_met_phi_centrality', 'DER_lep_eta_centrality', 'PRI_tau_pt', 'PRI_tau_eta', 'PRI_tau_phi', 'PRI_lep_pt', 'PRI_lep_eta', 'PRI_lep_phi', 'PRI_met', 'PRI_met_phi', 'PRI_met_sumet', 'PRI_jet_num', 'PRI_jet_leading_pt', 'PRI_jet_leading_eta', 'PRI_jet_leading_phi', 'PRI_jet_subleading_pt', 'PRI_jet_subleading_eta', 'PRI_jet_subleading_phi', 'PRI_jet_all_pt']\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additive binarization of NaN values\n",
    "feats_binarization = ['DER_mass_mmc','DER_deltaeta_jet_jet','PRI_jet_leading_pt']\n",
    "\n",
    "# removing unnecessary features\n",
    "feats_removal = ['DER_deltaeta_jet_jet','DER_mass_jet_jet','DER_prodeta_jet_jet','DER_lep_eta_centrality',\n",
    "                 'PRI_jet_leading_pt','PRI_jet_leading_eta','PRI_jet_leading_phi','PRI_jet_subleading_pt',\n",
    "                 'PRI_jet_subleading_eta','PRI_jet_subleading_phi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling case by case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling case A\n",
    "X_A = X.copy()\n",
    "\n",
    "# handling case B\n",
    "X_B = X.copy()\n",
    "X_B, mean_B, std_B = standardize(X_B)\n",
    "X_B = np.c_[np.ones(len(y)), X_B]\n",
    "\n",
    "# handling case C\n",
    "X_C = X.copy()\n",
    "X_C = replace_NaN_by_median(X_C)\n",
    "X_C, mean_C, std_C = standardize(X_C)\n",
    "X_C = np.c_[np.ones(len(y)), X_C]\n",
    "\n",
    "# handling case D\n",
    "X_D = X.copy()\n",
    "X_D, features_D = binarize_undefined(X_D, features, feats_binarization)\n",
    "X_D, features_D = remove_features(X_D, features_D, feats_removal)\n",
    "X_D = replace_NaN_by_median(X_D) # only for DER_mass_mmc\n",
    "X_D, mean_D, std_D = standardize(X_D)\n",
    "X_D = np.c_[np.ones(len(y)), X_D]\n",
    "\n",
    "# handling case E\n",
    "# in this model, if 'DER_mass_mmc' (first feature) is NaN, we predict background\n",
    "X_E = X.copy()\n",
    "X_E, _ = remove_features(X_E, features, feats_removal)\n",
    "#X_E, mean_E, std_E = standardize(X_E)\n",
    "X_E = np.c_[np.ones(len(y)), X_E]\n",
    "\n",
    "# handling case F\n",
    "X_F = X.copy()\n",
    "\n",
    "# handling case G\n",
    "X_G = X.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A - base\n",
    "* B - base + offset + standardisation\n",
    "* C - base + offset + standardisation + NaN to median\n",
    "* D - base + offset + standardisation + additive binarization + removal of 10 NaN values + median for DER_mass_mmc\n",
    "* E - C or D + decision tree\n",
    "* F - E + feature augmentation (L2 Kernels)\n",
    "* G - E + feature augmentation (L1 polynomial manually coded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84796\n",
      "0.84743\n",
      "0.84757\n",
      "0.847405\n",
      "0.84779\n",
      "0.84757\n",
      "0.847\n",
      "0.847435\n",
      "0.8474\n",
      "0.84753\n"
     ]
    }
   ],
   "source": [
    "# choice of classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier_E = LogisticRegressionDecisionTree(1)\n",
    "    \n",
    "accuracy_A = cross_validate(y, X_A, classifier, 0.8, 10)\n",
    "accuracy_B = cross_validate(y, X_B, classifier, 0.8, 10)\n",
    "accuracy_C = cross_validate(y, X_C, classifier, 0.8, 10)\n",
    "accuracy_D = cross_validate(y, X_D, classifier, 0.8, 10)\n",
    "accuracy_E = cross_validate(y, X_E, classifier_E, 0.8, 10)\n",
    "accuracy_F = cross_validate(y, X_F, classifier, 0.8, 10)\n",
    "accuracy_G = cross_validate(y, X_G, classifier, 0.8, 10)\n",
    "\n",
    "accuracy = [accuracy_A, accuracy_B, accuracy_C, accuracy_D,\n",
    "            accuracy_E, accuracy_F, accuracy_G]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_new: 4941487374.731 - f: 146868.184 - Backtracking...\n",
      "f_new: 1099132809.806 - f: 146868.184 - Backtracking...\n",
      "f_new: 244493738.677 - f: 146868.184 - Backtracking...\n",
      "f_new: 54399977.937 - f: 146868.184 - Backtracking...\n",
      "f_new: 12118589.865 - f: 146868.184 - Backtracking...\n",
      "f_new: 2715886.046 - f: 146868.184 - Backtracking...\n",
      "f_new: 632100.851 - f: 146868.184 - Backtracking...\n",
      "f_new: 194901.763 - f: 146868.184 - Backtracking...\n",
      "9 - loss: 134904.107\n",
      "10 - loss: 125776.930\n",
      "11 - loss: 124250.336\n",
      "12 - loss: 123663.301\n",
      "13 - loss: 122749.062\n",
      "14 - loss: 121356.311\n",
      "15 - loss: 120575.879\n",
      "16 - loss: 120426.410\n",
      "17 - loss: 120272.887\n",
      "18 - loss: 120205.402\n",
      "19 - loss: 119523.480\n",
      "20 - loss: 118609.335\n",
      "f_new: 119075.977 - f: 118609.335 - Backtracking...\n",
      "22 - loss: 118486.400\n",
      "23 - loss: 118466.131\n",
      "24 - loss: 118437.518\n",
      "25 - loss: 118426.881\n",
      "26 - loss: 118345.738\n",
      "27 - loss: 118003.025\n",
      "f_new: 118488.018 - f: 118003.025 - Backtracking...\n",
      "29 - loss: 117985.056\n",
      "30 - loss: 117976.170\n",
      "31 - loss: 117970.764\n",
      "32 - loss: 117967.877\n",
      "33 - loss: 117964.986\n",
      "34 - loss: 117866.741\n",
      "f_new: 117923.464 - f: 117866.741 - Backtracking...\n",
      "36 - loss: 117849.080\n",
      "37 - loss: 117834.411\n",
      "38 - loss: 117830.995\n",
      "39 - loss: 117829.485\n",
      "40 - loss: 117828.516\n",
      "41 - loss: 117827.549\n",
      "42 - loss: 117781.229\n",
      "f_new: 117841.441 - f: 117781.229 - Backtracking...\n",
      "44 - loss: 117776.486\n",
      "45 - loss: 117772.866\n",
      "46 - loss: 117772.343\n",
      "47 - loss: 117771.741\n",
      "48 - loss: 117771.518\n",
      "49 - loss: 117771.149\n",
      "50 - loss: 117767.527\n",
      "51 - loss: 117763.067\n",
      "52 - loss: 117762.655\n",
      "53 - loss: 117761.832\n",
      "54 - loss: 117761.479\n",
      "55 - loss: 117761.329\n",
      "56 - loss: 117761.232\n",
      "57 - loss: 117759.339\n",
      "58 - loss: 117757.654\n",
      "59 - loss: 117757.151\n",
      "60 - loss: 117756.874\n",
      "61 - loss: 117756.737\n",
      "62 - loss: 117756.616\n",
      "63 - loss: 117755.918\n",
      "64 - loss: 117755.656\n",
      "65 - loss: 117754.731\n",
      "66 - loss: 117754.680\n",
      "67 - loss: 117754.660\n",
      "68 - loss: 117754.576\n",
      "69 - loss: 117754.478\n",
      "70 - loss: 117754.318\n",
      "71 - loss: 117754.203\n",
      "72 - loss: 117754.154\n",
      "73 - loss: 117754.117\n",
      "74 - loss: 117754.067\n",
      "75 - loss: 117754.019\n",
      "76 - loss: 117754.003\n",
      "77 - loss: 117753.991\n",
      "78 - loss: 117753.977\n",
      "79 - loss: 117753.154\n",
      "f_new: 117755.829 - f: 117753.154 - Backtracking...\n",
      "81 - loss: 117753.145\n",
      "82 - loss: 117753.136\n",
      "83 - loss: 117753.135\n",
      "84 - loss: 117753.133\n",
      "85 - loss: 117753.097\n",
      "86 - loss: 117753.071\n",
      "87 - loss: 117753.040\n",
      "88 - loss: 117753.035\n",
      "89 - loss: 117753.034\n",
      "90 - loss: 117753.033\n",
      "91 - loss: 117753.033\n",
      "92 - loss: 117753.026\n",
      "93 - loss: 117752.998\n",
      "f_new: 117753.657 - f: 117752.998 - Backtracking...\n",
      "95 - loss: 117752.998\n",
      "96 - loss: 117752.998\n",
      "97 - loss: 117752.998\n",
      "98 - loss: 117752.998\n",
      "99 - loss: 117752.998\n",
      "100 - loss: 117752.998\n",
      "101 - loss: 117752.998\n",
      "102 - loss: 117752.998\n",
      "103 - loss: 117752.998\n",
      "104 - loss: 117752.998\n",
      "105 - loss: 117752.998\n",
      "106 - loss: 117752.998\n",
      "107 - loss: 117752.998\n",
      "108 - loss: 117752.998\n",
      "109 - loss: 117752.998\n",
      "110 - loss: 117752.998\n",
      "111 - loss: 117752.998\n",
      "112 - loss: 117752.998\n",
      "113 - loss: 117752.998\n",
      "114 - loss: 117752.998\n",
      "115 - loss: 117752.998\n",
      "116 - loss: 117752.998\n",
      "117 - loss: 117752.998\n",
      "118 - loss: 117752.998\n",
      "119 - loss: 117752.998\n",
      "f_new: 117752.998 - f: 117752.998 - Backtracking...\n",
      "121 - loss: 117752.998\n",
      "122 - loss: 117752.998\n",
      "123 - loss: 117752.998\n",
      "124 - loss: 117752.998\n",
      "125 - loss: 117752.998\n",
      "f_new: 117752.998 - f: 117752.998 - Backtracking...\n",
      "127 - loss: 117752.998\n",
      "128 - loss: 117752.998\n",
      "129 - loss: 117752.998\n",
      "130 - loss: 117752.998\n",
      "131 - loss: 117752.998\n",
      "132 - loss: 117752.998\n",
      "133 - loss: 117752.998\n",
      "134 - loss: 117752.998\n",
      "135 - loss: 117752.998\n",
      "136 - loss: 117752.998\n",
      "137 - loss: 117752.998\n",
      "138 - loss: 117752.998\n",
      "139 - loss: 117752.998\n",
      "140 - loss: 117752.998\n",
      "141 - loss: 117752.998\n",
      "142 - loss: 117752.998\n",
      "f_new: 117752.998 - f: 117752.998 - Backtracking...\n",
      "144 - loss: 117752.998\n",
      "Problem solved up to optimality tolerance 0.010\n",
      "0.743232\n"
     ]
    }
   ],
   "source": [
    "classifier_E = LogisticRegressionDecisionTree(1, max_evaluations=300, verbose=True)\n",
    "y_E = y[X_E[:,1] != -999]\n",
    "X_L = X_E[X_E[:,1] != -999,:]\n",
    "standard,_,_ = standardize(X_L[:,1:])\n",
    "X_S = np.c_[np.ones(len(y_E)), standard]\n",
    "y_eval = np.r_[y_E, y[X_E[:,1] == -999]]\n",
    "X_eval = np.r_[X_S, X_E[X_E[:,1] == -999,:]]\n",
    "\n",
    "\"\"\"\n",
    "kernel = LeastSquaresKernel(Kernel.kernel_poly)\n",
    "kernel.predict(y_E, X_E, X_E, 2)\n",
    "print(np.mean(y_E == kernel.predict(y_E, X_E, X_E, 2)))\n",
    "\"\"\"\n",
    "\n",
    "classifier_E.fit(y_E, X_S)\n",
    "print(np.mean(y_eval == classifier_E.predict(X_eval))) \n",
    "\n",
    "#classifier_E.fit(y_E,X_L)\n",
    "#print(np.mean(y_E == classifier_E.predict(X_L)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x1512989bf28>,\n",
       "  <matplotlib.lines.Line2D at 0x151298692b0>,\n",
       "  <matplotlib.lines.Line2D at 0x15105af9668>,\n",
       "  <matplotlib.lines.Line2D at 0x15105af99b0>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b02da0>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b02e80>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b14518>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b14860>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b20c50>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b20f98>,\n",
       "  <matplotlib.lines.Line2D at 0x15105af23c8>,\n",
       "  <matplotlib.lines.Line2D at 0x15105af2710>,\n",
       "  <matplotlib.lines.Line2D at 0x15135c47b00>,\n",
       "  <matplotlib.lines.Line2D at 0x15135c47e48>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x1514bafd1d0>,\n",
       "  <matplotlib.lines.Line2D at 0x15129869908>,\n",
       "  <matplotlib.lines.Line2D at 0x15105af9cf8>,\n",
       "  <matplotlib.lines.Line2D at 0x15105af9dd8>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b07470>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b077b8>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b14ba8>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b14ef0>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b26320>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b26668>,\n",
       "  <matplotlib.lines.Line2D at 0x15105af2a58>,\n",
       "  <matplotlib.lines.Line2D at 0x15105af2da0>,\n",
       "  <matplotlib.lines.Line2D at 0x15135c47f28>,\n",
       "  <matplotlib.lines.Line2D at 0x15135c50518>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x1512989bb38>,\n",
       "  <matplotlib.lines.Line2D at 0x15105af9320>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b02a58>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b07ef0>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b20908>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b26da0>,\n",
       "  <matplotlib.lines.Line2D at 0x15135c477b8>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x15129869c50>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b023c8>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b07b00>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b14fd0>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b269b0>,\n",
       "  <matplotlib.lines.Line2D at 0x15105af2e80>,\n",
       "  <matplotlib.lines.Line2D at 0x15135c50860>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x15129869f98>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b02710>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b07e48>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b205c0>,\n",
       "  <matplotlib.lines.Line2D at 0x15105b26cf8>,\n",
       "  <matplotlib.lines.Line2D at 0x15135c47470>,\n",
       "  <matplotlib.lines.Line2D at 0x15135c50ba8>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(accuracy, vert=False, labels=['A','B','C','D','E','F','G'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
